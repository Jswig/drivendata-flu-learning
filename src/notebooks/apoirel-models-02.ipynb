{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python_defaultSpec_1595281887377",
   "display_name": "Python 3.7.7 64-bit ('flu-shot-learning': conda)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import KNNImputer, SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, balanced_accuracy_score\n",
    "from sklearn.model_selection import cross_validate, cross_val_score, StratifiedKFold\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "import optuna\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/raw'\n",
    "X_train = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, 'training_set_features.csv')\n",
    ").drop('respondent_id',axis =1)\n",
    "\n",
    "X_test = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, 'test_set_features.csv')\n",
    ").drop('respondent_id',axis =1)\n",
    "\n",
    "y_train = pd.read_csv(\n",
    "    os.path.join(DATA_PATH, 'training_set_labels.csv')\n",
    ").drop('respondent_id',axis =1)\n",
    "\n",
    "sub = pd.read_csv(os.path.join(DATA_PATH, 'submission_format.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "Common preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_features = X_train.columns[X_train.dtypes != \"object\"].values\n",
    "cat_features = X_train.columns[X_train.dtypes == \"object\"].values\n",
    "\n",
    "num_transformer = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('impute', KNNImputer(n_neighbors = 10))\n",
    "])\n",
    "\n",
    "cat_transformer = Pipeline([\n",
    "    ('impute', SimpleImputer(strategy = 'constant', fill_value = 'missing')),\n",
    "    ('encode', OneHotEncoder(drop = 'first'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    ('num', num_transformer, num_features),\n",
    "    ('cat', cat_transformer, cat_features)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "\n",
    "As the hyperparameter space is more complex for the random forest \n",
    "(at least 4 hyperparameters to examine, vs just $C$ for logistic regression)\n",
    "we'll use Bayesian optimization with `optuna` to find suitable hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_func(trial, X, y):\n",
    "    \n",
    "    params = {\n",
    "        'criterion': trial.suggest_categorical('criterion', ['gini', 'entropy']),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1500),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 15),\n",
    "        'max_features': trial.suggest_uniform('max_features', 0.1, 1.0)\n",
    "    }\n",
    "\n",
    "    rf_model = Pipeline([\n",
    "        ('pre', preprocessor),\n",
    "        ('rf', MultiOutputClassifier(RandomForestClassifier(**params)))\n",
    "    ])\n",
    "    cv_score = cross_val_score(\n",
    "        X = X,\n",
    "        y = y,\n",
    "        scoring = 'roc_auc',\n",
    "        estimator = rf_model,\n",
    "        cv = 5 # cannot use stratified k-fold in multilabel problems \n",
    "    )\n",
    "    \n",
    "    return np.mean(cv_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": "[I 2020-07-20 15:10:24,895] Finished trial#0 with value: 0.8519623655058026 with parameters: {'criterion': 'entropy', 'n_estimators': 1254, 'max_depth': 10, 'max_features': 0.5478300585833582}. Best is trial#0 with value: 0.8519623655058026.\n[I 2020-07-20 15:15:00,329] Finished trial#1 with value: 0.8523749236382809 with parameters: {'criterion': 'gini', 'n_estimators': 306, 'max_depth': 13, 'max_features': 0.30897436493668373}. Best is trial#1 with value: 0.8523749236382809.\n"
    }
   ],
   "source": [
    "objective = partial(objective_func,X = X_train, y = y_train)\n",
    "study = optuna.create_study(direction = 'maximize')\n",
    "study.optimize(objective, n_trials = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "{'criterion': 'gini',\n 'n_estimators': 306,\n 'max_depth': 13,\n 'max_features': 0.30897436493668373}"
     },
     "metadata": {},
     "execution_count": 15
    }
   ],
   "source": [
    "params = study.best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "0.8523749236382809"
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "study.best_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This score is better than our previous CV score with logistic regression, \n",
    "build a submission using these parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_model = Pipeline([\n",
    "    ('pre', preprocessor),\n",
    "    ('rf', MultiOutputClassifier(RandomForestClassifier(**params)))\n",
    "])\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "preds = rf_model.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub['h1n1_vaccine'] = preds[0][:,1]\n",
    "sub['seasonal_vaccine'] = preds[1][:,1]\n",
    "sub.to_csv('../../output/baseline_pred.csv', index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ]
}